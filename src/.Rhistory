#' trainDat <- extract(studyArea,pts,df=TRUE)
#' trainDat <- merge(trainDat,pts,by.x="ID",by.y="ID")
#' variables <- c("DEM","Easting","Northing")
#'
#' #train:
#' set.seed(100)
#' model <- train(trainDat[,which(names(trainDat)%in%variables)],
#' trainDat$VW,method="rf",importance=TRUE,tuneLength=1)
#'
#' #Preedict and calculate RII
#' prediction <- predict(studyArea,model)
#' RII <- uncertainty(trainDat,studyArea,model=model,variables=variables)
#' DOA(prediction,RII)
#' }
#' @export DOA
#' @aliases DOA
DOA <- function (prediction,rii,
threshold="90%",
col="grey",
returnRaster=FALSE, ...){
requireNamespace("latticeExtra")
if (threshold=="sd"){
if(is.null(attributes(rii)$train_dist_sd)||
is.null(attributes(rii)$train_dist_mean)){
stop("mean and sd not available for rii.")
}
# hier noch hin: wenn atriubutes empty Warnung
threshold <- attributes(rii)$train_dist_sd/
attributes(rii)$train_dist_mean
}
if (threshold=="mean"){
if(is.null(attributes(rii)$train_dist_mean)){
stop("mean not available for rii.")
}
threshold <- 0
}
if(threshold=="90%"){
threshold <- attributes(rii)$trainDist_quantiles[,
colnames(attributes(rii)$trainDist_quantiles)=="90%"]/
attributes(rii)$train_dist_mean
}
masklayer <- rii
raster::values(masklayer) <- 1
raster::values(masklayer)[raster::values(rii)<=threshold] <- NA
masklayer <- raster::mask(masklayer,prediction)
if(sum(!is.na(values(masklayer)))==0){
out_plt <- sp::spplot(prediction, ...)
}else{
out_plt <- sp::spplot(prediction, ...)+
sp::spplot(masklayer,col.regions=col)
}
#  print(out_plt)
if (returnRaster){
result <- prediction
result[rii>threshold] <- NA
return(list("DOA"=result,
"DOA_plot"=out_plt))
}else{
return(out_plt)
}
}
DOA(compare$prediction,compare$uncertainty,threshold=20)
DOA(compare$prediction,compare$uncertainty,threshold=1)
DOA(compare$prediction,compare$uncertainty,threshold=0)
test=stack("/home/hanna/Documents/Presentations/Paper/in_prep/MappingUncertainty/Supplement/compare.grd")
test$uncertainty
attributes(test$uncertainty)
str_detect("90%","%")
?grepl
grepl("90%", "%")
grepl("%","90%")
grep("%","90%")
sub("%", "", "90%")
#' Visualize Domain of applicability
#'
#' @description plot applicability
#' @param prediction Raster layer with the prediction values
#' @param rii Raster layer with the risk of inapplicability
#' @param col character. Color for out of domain of applicability
#' @param threshold either "sd", "mean" or a user defined value
#' @returnRaster plot Logical. Should the raster layer be return in addition?
#' @param ... other argument passed to spplot
#' @return RasterLayer
#' @author
#' Hanna Meyer
#' @examples
#' \dontrun{
#' library(sf)
#' library(raster)
#' library(caret)
#'
#' # prepare sample data:
#' dat <- get(load(system.file("extdata","Cookfarm.RData",package="CAST")))
#' dat <- aggregate(dat[,c("VW","Easting","Northing")],by=list(as.character(dat$SOURCEID)),mean)
#' pts <- st_as_sf(dat,coords=c("Easting","Northing"))
#' pts$ID <- 1:nrow(pts)
#' studyArea <- stack(system.file("extdata","predictors_2012-03-25.grd",package="CAST"))[[1:8]]
#' trainDat <- extract(studyArea,pts,df=TRUE)
#' trainDat <- merge(trainDat,pts,by.x="ID",by.y="ID")
#' variables <- c("DEM","Easting","Northing")
#'
#' #train:
#' set.seed(100)
#' model <- train(trainDat[,which(names(trainDat)%in%variables)],
#' trainDat$VW,method="rf",importance=TRUE,tuneLength=1)
#'
#' #Preedict and calculate RII
#' prediction <- predict(studyArea,model)
#' RII <- uncertainty(trainDat,studyArea,model=model,variables=variables)
#' DOA(prediction,RII)
#' }
#' @export DOA
#' @aliases DOA
DOA <- function (prediction,rii,
threshold="90%",
col="grey",
returnRaster=FALSE, ...){
requireNamespace("latticeExtra")
if (threshold=="sd"){
if(is.null(attributes(rii)$train_dist_sd)||
is.null(attributes(rii)$train_dist_mean)){
stop("mean and sd not available for rii.")
}
# hier noch hin: wenn atriubutes empty Warnung
threshold <- attributes(rii)$train_dist_sd/
attributes(rii)$train_dist_mean
}
if (threshold=="mean"){
if(is.null(attributes(rii)$train_dist_mean)){
stop("mean not available for rii.")
}
threshold <- 0
}
if(grepl("%",threshold)){
threshold <- attributes(rii)$trainDist_quantiles[,
colnames(attributes(rii)$trainDist_quantiles)==threshold]/
attributes(rii)$train_dist_mean
}
masklayer <- rii
raster::values(masklayer) <- 1
raster::values(masklayer)[raster::values(rii)<=threshold] <- NA
masklayer <- raster::mask(masklayer,prediction)
if(sum(!is.na(values(masklayer)))==0){
out_plt <- sp::spplot(prediction, ...)
}else{
out_plt <- sp::spplot(prediction, ...)+
sp::spplot(masklayer,col.regions=col)
}
#  print(out_plt)
if (returnRaster){
result <- prediction
result[rii>threshold] <- NA
return(list("DOA"=result,
"DOA_plot"=out_plt))
}else{
return(out_plt)
}
}
DOA(compare$prediction,compare$uncertainty,threshold=0)
DOA(compare$prediction,compare$uncertainty,threshold="75%")
DOA(compare$prediction,compare$uncertainty,threshold="90%")
DOA(compare$prediction,compare$uncertainty,threshold="25%")
DOA(compare$prediction,compare$uncertainty,threshold="50%")
DOA(compare$prediction,compare$uncertainty,threshold="90%")
DOA(compare$prediction,compare$uncertainty,threshold="95%")
DOA(compare$prediction,compare$uncertainty,threshold="75%")
DOA(compare$prediction,compare$uncertainty,threshold="90%")
DOA(compare$prediction,compare$uncertainty,threshold="mean")
?rasterize
samplepoints
predictors$distance <- predictors[[1]]
values(predictors$distance) <- NA
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance)),1,100)
predictors$distance <- predictors[[1]]
values(predictors$distance) <- NA
samplepoints$ID <- 1:nrow(samplepoints)
samplepoints$ID <- 1:length(samplepoints)
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance)),1,100)
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance,field="ID")),1,100)
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance,field="")),1,100)
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance,field=NULL)),1,100)
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance,field=1)),1,100)
samplepoints
?spsample
data(meuse.riv)
meuse.sr = SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)), "x")))
plot(meuse.sr)
test=spsample(meuse.sr, n = 1000, "regular"))
data(meuse.riv)
meuse.sr = SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)), "x")))
plot(meuse.sr)
test=spsample(meuse.sr, n = 1000, "regular")
samplepoints <- spsample(mask,npoints,"random")
predictors$distance <- stretch(raster::distance(rasterize(samplepoints,predictors$distance,field=1)),1,100)
spplot(predictors$distance)
samplepoints
n <- 200
set.seed(35233)
x <- mvtnorm::rmvnorm(n = n, mean = c(0, 0),
sigma = rbind(c(1.5, 0.25), c(0.25, 0.5)))
head(x)
x <- trainDat[,2:(ncol(trainDat)-1)]
load("/home/hanna/Documents/Presentations/Paper/in_prep/MappingUncertainty/Supplement/trainDat.RData")
x <- trainDat[,2:(ncol(trainDat)-1)]
# Compute kde for a diagonal bandwidth matrix (trivially positive definite)
#H <- diag(c(1.25, 0.75))
kde <- ks::kde(x = x)
# Compute kde for a diagonal bandwidth matrix (trivially positive definite)
#H <- diag(c(1.25, 0.75))
kde <- ks::kde(x = x[,2:6])
# The eval.points slot contains the grids on x and y
str(kde$eval.points)
# The grids in kde$eval.points are crossed in order to compute a grid matrix
# where to evaluate the estimate
dim(kde$estimate)
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate,
col = viridis::viridis(20), xlab = "x", ylab = "y")
kde$estimate
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate)
plot(kde)
# Compute kde for a diagonal bandwidth matrix (trivially positive definite)
#H <- diag(c(1.25, 0.75))
kde <- ks::kde(x = x[,2:4])
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate,
col = viridis::viridis(20), xlab = "x", ylab = "y")
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate)
plot(kde)
str(kde$eval.points)
str(kde$estimate)
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate[,1:2],
col = viridis::viridis(20), xlab = "x", ylab = "y")
str(kde$estimate[,1:2])
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate[[1:2]],
col = viridis::viridis(20), xlab = "x", ylab = "y")
kde$estimate[[1:2]]
kde$estimate[[1]]
str(kde$estimate)
data.frame(kde$estimate)
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate[,,1],
col = viridis::viridis(20), xlab = "x", ylab = "y")
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate[,,2],
col = viridis::viridis(20), xlab = "x", ylab = "y")
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate[,,],
col = viridis::viridis(20), xlab = "x", ylab = "y")
# Compute kde for a diagonal bandwidth matrix (trivially positive definite)
#H <- diag(c(1.25, 0.75))
kde <- ks::kde(x = x[,c(2,10)])
# The eval.points slot contains the grids on x and y
str(kde$eval.points)
# The grids in kde$eval.points are crossed in order to compute a grid matrix
# where to evaluate the estimate
dim(kde$estimate)
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate,
col = viridis::viridis(20), xlab = "x", ylab = "y")
points(kde$x) # The data is returned in $x
# Manual plotting using the kde object structure
image(kde$eval.points[[1]], kde$eval.points[[2]], kde$estimate,
col = viridis::viridis(20), xlab = "x", ylab = "y")
?kde
kde$eval.points[[1]]
kde$eval.points[[2]]
load("/home/hanna/Documents/Presentations/Paper/in_prep/MappingUncertainty/Supplement/trainDat.RData")
#n <- 200
#set.seed(35233)
#x <- mvtnorm::rmvnorm(n = n, mean = c(0, 0),
#                      sigma = rbind(c(1.5, 0.25), c(0.25, 0.5)))
x <- trainDat[,2:(ncol(trainDat)-1)]
# Compute kde for a diagonal bandwidth matrix (trivially positive definite)
#H <- diag(c(1.25, 0.75))
kde <- ks::kde(x = x[,c(2,10)])
predict(kde,data.frame(-100:500,-100:500))
test=predict(kde,c(-100,300))
test=predict(kde,x=c(-100,300))
test
predict(kde,x=c(200,300)
)
test=predict(kde,x=data.frame(-100:500,-100:500))
head(test)
summary(test)
image(-100:500,-100:500, test,
col = viridis::viridis(20), xlab = "x", ylab = "y")
image(-100:500,-100:500, test)
tmp=data.frame(-100:500,-100:500)
str(tmp)
str(test)
tmp <- data.frame(-100:500,-100:500)
head(tmp)
image(tmp[,1],tmp[,2] test,
col = viridis::viridis(20), xlab = "x", ylab = "y")
image(tmp[,1],tmp[,2], test,
col = viridis::viridis(200), xlab = "x", ylab = "y")
kde$estimate
str(kde$estimate)
?knn
library(class)
?knn
library(fractal)
install.packages("fractal")
library(fractal)
embedding <- embedSeries( beamchaos, dim = 3, tlag = 10 )
nn <- findNeighbors( embedding, n.neighbor=10, olag=1 )
## Using the same data, find only those neighbors
## within a distance 0.1 of the original points
## based on an L-infinity metric
nn.dist <- findNeighbors( embedding, max.distance=0.1,
metric=Inf, olag=1 )
nn.dist
dat <- trainDat[,2:4]
head(dat)
nn <- findNeighbors( dat, n.neighbor=10, olag=1 )
head(matrix(dat))
head(as.matrix(dat))
nn <- findNeighbors( as.matrix(dat), n.neighbor=10, olag=1 )
dat <- as.matrix(trainDat[,2:4])
str(dat)
nn.dist <- findNeighbors( dat, max.distance=0.1)
embedding <- embedSeries( beamchaos, dim = 3, tlag = 10 )
nn <- findNeighbors( embedding, n.neighbor=10, olag=1 )
## Using the same data, find only those neighbors
## within a distance 0.1 of the original points
## based on an L-infinity metric
nn.dist <- findNeighbors( embedding, max.distance=0.1,
metric=Inf, olag=1 )
# }
nn.dist
c(1:10)
1/10
test=data.frame("a"=1:3,"b"=1:3)
test2=data.frame("test","c"=NA)
test2
test
test2=data.frame(test,"c"=NA)
test2
library(Metrics)
rmse
mse
data(iris)
head(iris)
model <- train(iris[,1:4],iris$Species,method="rf")
library(caret)
model <- train(iris[,1:3],iris[,4],method="rf")
nrow(iris)
model <- train(iris[1:100,1:4],iris$Species,method="rf")
model <- train(iris[,1:4],iris$Species,method="rf")
summary(iris)
plot(iris$Sepal.Length,iris$Petal.Length)
names(iris)
model <- train(iris[,c(1,3)],iris$Species,method="rf")
newdat <- data.frame("Sepal.Length"=c(5.5,6.5,7.5),
"Petal.Length"=c(3,3,3))
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
pred_all
model <- train(iris[,c(1,3)],iris[,4],method="rf")
newdat <- data.frame("Sepal.Length"=c(5.5,6.5,7.5),
"Petal.Length"=c(3,3,3))
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
pred_all
sds <-  apply(pred_all$individual,1,sd)
sds
newdat <- data.frame("Sepal.Length"=c(7.5,1,5.5,6.5,7.5),
"Petal.Length"=c(6,6,3,3,3))
points(newdat,col="red")
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
sds
points(newdat,col="red",cex=sds)
points(newdat,col="red",cex=sds*10)
newdat <- data.frame("Sepal.Length"=c(7.5,4.5,5.5,6.5,7.5),
"Petal.Length"=c(6,6,3,3,3))
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
points(newdat,col="red",cex=sds*10)
plot(iris$Sepal.Length,iris$Petal.Length)
points(newdat,col="red",cex=sds*10)
newdat <- data.frame("Sepal.Length"=c(7.5,4.5,5.5,6.5,7.5,6,5.5),
"Petal.Length"=c(6,6,3,3,3,5,1))
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
plot(iris$Sepal.Length,iris$Petal.Length)
points(newdat,col="red",cex=sds*10)
newdat <- data.frame("Sepal.Length"=seq(4.5,8,0.2),
"Petal.Length"=seq(1,7,0.2))
newdat <- expand.grid(newdat)
newdat <- data.frame("Sepal.Length"=seq(1,8,0.2),
"Petal.Length"=seq(1,8,0.2))
newdat <- expand.grid(newdat)
head(newdat)
pred_all <- predict(model$finalModel,newdat,predict.all=TRUE)
sds <-  apply(pred_all$individual,1,sd)
plot(iris$Sepal.Length,iris$Petal.Length)
points(newdat,col="red",cex=sds*10)
viridis(100)
library(viridis)
viridis(100)
sds
sds*10
sds*100
round(sds*100,0)
points(newdat,col="red",col=viridis(100)[round(sds*100,0)])
points(newdat,col=viridis(100)[round(sds*100,0)])
plot(iris$Sepal.Length,iris$Petal.Length)
points(newdat,col=viridis(100)[round(sds*100,0)])
points(newdat,col=viridis(50)[round(sds*100,0)])
plot(iris$Sepal.Length,iris$Petal.Length)
points(newdat,col=viridis(50)[round(sds*100,0)])
plot(iris$Sepal.Length,iris$Petal.Length,col=iris[,4])
plot(iris$Sepal.Length,iris$Petal.Length,col=viridis(50)[iris[,4]*10])
plot(iris$Sepal.Length,iris$Petal.Length,col=viridis(50)[iris[,4]*20])
2.46/2.29
Sys.getenv("USER")
library(ggplot2)
library(reshape2)
dat=get(load("/home/hanna/Documents/Presentations/Paper/in_prep/MappingUncertainty/Deprecated_Supplement/resultsTable_large_90.RData"))
means <- as.data.frame(matrix(unlist(dat$meansPCA),ncol=2,byrow = T))
sds <- as.data.frame(matrix(unlist(dat$sdPCA),ncol=2,byrow = T))
# these are the settings of the specific case study shown in the paper:
caseStudy <- dat[dat$npoints==50&dat$seed==10&
sds[,1]==2&sds[,2]==2&
means[,1]==3&means[,2]==-1,]
par(mfrow=c(1,2),mar=c(7,3,1,1))
boxplot(dat$model_RMSE,dat$PredError_RMSE,
dat$`PredErrorAOA_RMSE`,
dat$`PredErrorNOTAOA_RMSE`,
names=c("CV RMSE","RMSE all", "RMSE AOA",
"RMSE !AOA"),las=2,notch=T)
boxplot(dat$model_R2,dat$PredError_R2,
dat$`PredErrorAOA_R2`,
dat$`PredErrorNOTAOA_R2`,
names=c("CV R2","R2 all", "R2 AOA",
"R2 !AOA"),las=2,notch=T)
par(mfrow=c(1,2))
lim <- c(min(c(dat$model_RMSE,dat$`PredErrorAOA_RMSE`)),
max(c(dat$model_RMSE,dat$`PredErrorAOA_RMSE`)))
plot(dat$model_RMSE~dat$`PredErrorAOA_RMSE`,
xlim=lim,ylim=lim,
xlab="RMSE prediction (AOA)",ylab="RMSE model CV")
points(caseStudy$model_RMSE~caseStudy$`PredErrorAOA_RMSE`,col="red",pch=16)
legend("topleft",legend="a",bty="n")
abline(0,1)
lim <- c(min(c(dat$model_RMSE,dat$`PredErrorNOTAOA_RMSE`),na.rm=T),
max(c(dat$model_RMSE,dat$`PredErrorNOTAOA_RMSE`),na.rm=T))
plot(dat$model_RMSE~dat$`PredErrorNOTAOA_RMSE`,
xlim=lim,ylim=lim,
xlab="RMSE prediction (outside AOA)",ylab="RMSE model CV")
points(caseStudy$model_RMSE~caseStudy$`PredErrorNOTAOA_RMSE`,col="red",pch=16)
legend("topleft",legend="b",bty="n")
abline(0,1)
library(raster)
test=raster("/home/hanna/Documents/Lehre/Kurse/2019_WiSe/R-Spatial/data/W07/dgm_noProj.tif")
test
library(sf)
wald=st_read("/home/hanna/Documents/Lehre/Kurse/2020_SoSe/Fernerkundung/data/Woche_01/wald_muenster.shp")
projection(test)=" +proj=utm +zone=32 +ellps=GRS80 +units=m +no_defs"
test
writeRaster(test,"/home/hanna/Documents/Lehre/Kurse/2020_SoSe/Fernerkundung/data/Woche_01/dem_muenster.tif")
test
library(mapview)
mapview(plot)
mapview(test)
zx_means <- (colMeans(zx, na.rm = TRUE))
zx <- replicate (5, rnorm(50))
zx_means <- (colMeans(zx, na.rm = TRUE))
boxplot(zx, horizontal = FALSE, outline = FALSE)
points(zx_means, pch = 22, col = "darkgrey", lwd = 7)
zx <- replicate (5, rnorm(50))
zx_means <- (colMeans(zx, na.rm = TRUE))
boxplot(zx, horizontal = FALSE, outline = FALSE)
lines(zx_means, col = "darkgrey", lwd = 7)
?train
library(caret)
?train
data(iris)
TrainData <- iris[,1:4]
TrainClasses <- iris[,5]
knnFit1 <- train(TrainData, TrainClasses,
method = "rf",
#preProcess = c("center", "scale"),
tuneLength = 2,
trControl = trainControl(method = "LOOCV"))
model=knnFit1
model$control$indexOut
CVfolds <- tryCatch(reshape2::melt(model$control$indexOut),
error=function(e) e)
nrow(CVfolds)>nrow(trainDist)
nrow(TrainData)
nrow(CVfolds)
getwd()
setwd("/home/hanna/Documents/Release/HannaMeyer/AOA_CaseStudy/src/")
library(ggplot2)
library(reshape2)
library(hydroGOF)
dat <- get(load("../data/resultsTable.RData"))
means <- as.data.frame(matrix(unlist(dat$meansPCA),ncol=2,byrow = T))
sds <- as.data.frame(matrix(unlist(dat$sdPCA),ncol=2,byrow = T))
# these are the settings of the specific case study shown in the paper:
caseStudy <- dat[dat$npoints==50&dat$seed==10&
sds[,1]==2&sds[,2]==2&
means[,1]==3&means[,2]==-1,]
head(dat)
plot(dat$RFSD_R2,dat$AOAI_R2)
boxplot(dat$RFSD_R2,dat$AOAI_R2)
boxplot(dat$RFSD_R2,dat$AOAI_R2,notch=T)
